{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc3c4967",
   "metadata": {},
   "source": [
    "# Projeto de Machine Learning (TP1) - Predição de Preços de Carros\n",
    "\n",
    "Este notebook implementa um modelo de machine learning para prever preços de carros usados baseado em suas características."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15472cd",
   "metadata": {},
   "source": [
    "## 1. Instalação de Dependências {#instalacao}\n",
    "\n",
    "Primeiro, vamos instalar todas as bibliotecas necessárias para o projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação das dependências (executar apenas uma vez)\n",
    "%pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d3f76",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Exploração dos Dados {#exploracao}\n",
    "\n",
    "Agora vamos carregar o dataset e fazer uma análise exploratória inicial para entender os dados com que estamos trabalhando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b939cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas e carregar dados\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o dataset (versão reduzida para performance)\n",
    "df = pd.read_csv(\"train_small.csv\")\n",
    "\n",
    "print(f\"Dataset carregado com {len(df)} registros\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b1cb1d",
   "metadata": {},
   "source": [
    "## 3. Preparação dos Dados {#preparacao}\n",
    "\n",
    "Agora vamos preparar os dados para o modelo, separando features (X) e target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf50158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"price\"])\n",
    "Y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c049cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# separar colunas por tipo de dados\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns  # colunas de texto/categoria\n",
    "numeric_cols = X.select_dtypes(exclude=[\"object\"]).columns      # colunas numéricas\n",
    "\n",
    "# criar preprocessador para tratar diferentes tipos de dados\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorias\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),  # converte categorias em 0s e 1s\n",
    "        (\"numericas\", \"passthrough\", numeric_cols)                                # mantem numeros como estao\n",
    "    ]\n",
    ")\n",
    "\n",
    "# pipeline completo: preprocessamento / modelo\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", LinearRegression())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ecec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Dividir dados em treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calcular erro (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "print(f\"RMSE do modelo baseline: ${rmse:,.2f}\\n\")\n",
    "\n",
    "print(\"Distribuição do preço (target):\")\n",
    "print(f\"Preço médio:   ${Y.mean():,.2f}\")\n",
    "print(f\"Mediana:       ${Y.median():,.2f}\")\n",
    "print(f\"25% percentil: ${Y.quantile(0.25):,.2f}\")\n",
    "print(f\"75% percentil: ${Y.quantile(0.75):,.2f}\")\n",
    "print(f\"Mínimo:        ${Y.min():,.2f}\")\n",
    "print(f\"Máximo:        ${Y.max():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13a1d72",
   "metadata": {},
   "source": [
    "## Pipeline KNN + Normalizaçao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "knn_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),   # mesmo One-Hot + num\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"knn\", KNeighborsRegressor())\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27704c7b",
   "metadata": {},
   "source": [
    "## 6. Otimizações de Performance\n",
    "\n",
    "Para melhorar a performance do modelo e reduzir o tempo de processamento, foram feitas as seguintes otimizações:\n",
    "\n",
    "- **Dataset reduzido**: Usando uma amostra de 15.000 registros (vs 188.533 originais)\n",
    "- **Grid de parâmetros simplificado**: Reduzindo o número de valores testados\n",
    "- **Cross-validation reduzida**: Usando 3 folds ao invés de 5\n",
    "- **Processamento paralelo**: Utilizando todos os cores disponíveis (`n_jobs=-1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(\n",
    "    knn_model,\n",
    "    X,\n",
    "    Y,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "\n",
    "rmse_scores = -scores\n",
    "\n",
    "print(\"RMSE por fold:\", rmse_scores)\n",
    "print(f\"RMSE médio: {rmse_scores.mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959175e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"knn__n_neighbors\": [3, 5, 7],\n",
    "    \"knn__weights\": [\"uniform\", \"distance\"],\n",
    "    \"knn__p\": [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    knn_model,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Iniciando GridSearchCV com dataset reduzido...\")\n",
    "grid_search.fit(X, Y)\n",
    "\n",
    "print(\"Melhor RMSE:\", -grid_search.best_score_)\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
